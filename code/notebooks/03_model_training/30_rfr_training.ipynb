{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Training a Random Forest Regressor for DACs on N-Doped Carbon Materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup: Imports and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#  Standard Library Imports\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import re\n",
    "import itertools as it\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#  Project Source Imports\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "sys.path.append(os.path.abspath(os.path.join('..', '..', 'src')))\n",
    "\n",
    "from vis import *\n",
    "from ml import *\n",
    "from settings import *\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#  Numerical & Data Manipulation\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.linalg import LinAlgWarning\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#  Plotting Libraries\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, plot\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.io as pio\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#  Machine Learning (Scikit-learn)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#  Notebook Environment Settings\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#  Warning Filters\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "warnings.filterwarnings(action=\"ignore\", category=LinAlgWarning, module=\"sklearn\")\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preapring the DACs on N-doped carbon datasets for LOGOCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Preparing DFT Energy Datasets with 10-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block of code loads preprocessed adsorption energy datasets from `.pkl` files and prepares them for **K-Fold cross-validation** using a custom utility (`add_cv_columns`). Each dataset is labeled and stored dynamically for convenient downstream use.\n",
    "\n",
    "> âš ï¸ **Note**: This code is currently commented out.  \n",
    "> To use it, **remove the comment symbols (`#`)** before executing.\n",
    "\n",
    "#### ğŸ› ï¸ Steps Performed:\n",
    "- Define the directory containing `.pkl` data files.\n",
    "- Load each dataset into memory.\n",
    "- Apply **K-Fold cross-validation** (with 10 splits).\n",
    "- Store each CV-ready DataFrame using both:\n",
    "  - Global variable assignment (e.g., `Edft_din6_df_kfold`)\n",
    "  - Central `dataframe_dict` for easier access.\n",
    "\n",
    "This step is **required before training the Random Forest Regressor (RFR)** on Kfold data.  \n",
    "â¡ï¸ **Also remember to uncomment the corresponding model training block below this section**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../../data/external/dacs_energies_out\"\n",
    "\n",
    "# Define the file names and corresponding variable names\n",
    "file_variables = {\n",
    "    \"Edacs_dft.pkl\": \"Edacs_dft\",\n",
    "    \"Edft_din6_as_df.pkl\":\"Edft_din6_as_df\",\n",
    "    \"Edft_din6_s_df.pkl\":\"Edft_din6_s_df\",\n",
    "    \"Edft_din4_x2_df.pkl\":\"Edft_din4_x2_df\",\n",
    "    \"Edft_din6_df.pkl\":\"Edft_din6_df\",\n",
    "    \"Edft_din6_s_din4_x2_df.pkl\":\"Edft_din6_s_din4_x2_df\",\n",
    "    \"Edft_din6_as_din4_x2_df.pkl\":\"Edft_din6_as_din4_x2_df\",\n",
    "    \"Edft_balanced_df.pkl\": \"Edft_balanced_df\"\n",
    "    } \n",
    "\n",
    "\n",
    "# Create an empty dictionary to store the DataFrames\n",
    "data_frames = {}\n",
    "\n",
    "# Iterate over the file_variables dictionary\n",
    "for file_name, variable_name in file_variables.items():\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    data_frame = pd.read_pickle(file_path)\n",
    "    data_frames[variable_name] = data_frame\n",
    "\n",
    "\n",
    "cv_setup = {\"cv_type\": \"kfold\", \"cv_spec\": 10}\n",
    "\n",
    "\n",
    "\n",
    "# cv_setup_metal = {\"cv_type\": \"logocv\", \"cv_spec\": \"metal\"}\n",
    "\n",
    "# Create a dictionary to store the dataframes for easy access\n",
    "dataframe_dict = {}\n",
    "\n",
    "# Iterate over the data_frames dictionary\n",
    "for key, df in data_frames.items():\n",
    "    # Apply the add_cv_columns function to each dataframe\n",
    "    kfold_df = add_cv_columns(df_in=df, cv_setup=cv_setup)\n",
    "    # Create a variable name based on the original dataframe name with \"_kfold\" appended\n",
    "    var_name = key + \"_kfold\"\n",
    "    # Assign the kfold dataframe to the dynamically\n",
    "    globals()[var_name] = kfold_df\n",
    "    \n",
    "    # Store the kfold dataframe in the dataframe dictionary\n",
    "    dataframe_dict[var_name] = kfold_df\n",
    "\n",
    "\n",
    "# TODO: Write within a loop and have access at any point of the code\n",
    "Edacs_dft_df_kfold = dataframe_dict[\"Edacs_dft_kfold\"]\n",
    "Edft_din6_as_df_kfold = dataframe_dict[\"Edft_din6_as_df_kfold\"]\n",
    "Edft_din6_s_df_kfold = dataframe_dict[\"Edft_din6_s_df_kfold\"]\n",
    "Edft_din4_x2_df_kfold = dataframe_dict[\"Edft_din4_x2_df_kfold\"]\n",
    "Edft_din6_df_kfold = dataframe_dict[\"Edft_din6_df_kfold\"]\n",
    "Edft_din6_s_din4_x2_df_kfold = dataframe_dict[\"Edft_din6_s_din4_x2_df_kfold\"]\n",
    "Edft_din6_as_din4_x2_df_kfold = dataframe_dict[\"Edft_din6_as_din4_x2_df_kfold\"]\n",
    "Edft_balanced_df_kfold= dataframe_dict[\"Edft_balanced_df_kfold\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Preparing DFT Energy Datasets with Dual Metal Leave-One-Group-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block loads adsorption energy datasets and applies **Leave-One-Group-Out cross-validation (LOGO-CV)** by metal identity using the `\"M1\"` group column.  \n",
    "The processed data is stored both as dynamically named variables and in a central dictionary for easy access.\n",
    "\n",
    "> âš ï¸ **Note**: This code is **commented out**.  \n",
    "> To use it, **uncomment** all relevant lines (remove `#` at the beginning of each line).\n",
    "\n",
    "#### âœ… What this code does:\n",
    "- Loads `.pkl` data files from a local directory\n",
    "- Applies LOGO-CV using a custom `add_cv_columns()` function\n",
    "- Stores the resulting DataFrames with `_logocv_metal` suffixes\n",
    "\n",
    "This step is **required before training the Random Forest Regressor (RFR)** on LOGO-CV data.  \n",
    "â¡ï¸ **Also remember to uncomment the corresponding model training block below this section**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"../../../data/external/dacs_energies_out\"\n",
    "\n",
    "# # Define the file names and corresponding variable names\n",
    "# file_variables = {\n",
    "#     \"Edacs_dft.pkl\": \"Edacs_dft\",\n",
    "#     \"Edft_din6_as_df.pkl\":\"Edft_din6_as_df\",\n",
    "#     \"Edft_din6_s_df.pkl\":\"Edft_din6_s_df\",\n",
    "#     \"Edft_din4_x2_df.pkl\":\"Edft_din4_x2_df\",\n",
    "#     \"Edft_din6_df.pkl\":\"Edft_din6_df\",\n",
    "#     \"Edft_din6_s_din4_x2_df.pkl\":\"Edft_din6_s_din4_x2_df\",\n",
    "#     \"Edft_din6_as_din4_x2_df.pkl\":\"Edft_din6_as_din4_x2_df\",\n",
    "#     \"Edft_balanced_df.pkl\": \"Edft_balanced_df\"\n",
    "\n",
    "#     } \n",
    "\n",
    "# # Create an empty dictionary to store the DataFrames\n",
    "# data_frames = {}\n",
    "\n",
    "# # Iterate over the file_variables dictionary\n",
    "# for file_name, variable_name in file_variables.items():\n",
    "#     file_path = os.path.join(data_dir, file_name)\n",
    "#     data_frame = pd.read_pickle(file_path)\n",
    "#     data_frames[variable_name] = data_frame\n",
    "\n",
    "# # Iterate over the file_variables dictionary\n",
    "# for file_name, variable_name in file_variables.items():\n",
    "#     file_path = os.path.join(data_dir, file_name)\n",
    "#     data_frame = pd.read_pickle(file_path)\n",
    "#     data_frames[variable_name] = data_frame\n",
    "\n",
    "\n",
    "# cv_setup = {\"cv_type\": \"logocv\", \"cv_spec\": 'M1'}\n",
    "\n",
    "\n",
    "# # Create a dictionary to store the dataframes for easy access\n",
    "# dataframe_dict = {}\n",
    "\n",
    "# # Iterate over the data_frames dictionary\n",
    "# for key, df in data_frames.items():\n",
    "#     # Apply the add_cv_columns function to each dataframe\n",
    "#     logocv_df = add_cv_columns(df_in=df, cv_setup=cv_setup)\n",
    "#     # Create a variable name based on the original dataframe name with \"_kfold\" appended\n",
    "#     var_name = key + \"_logocv_metal\"\n",
    "#     # Assign the kfold dataframe to the dynamically\n",
    "#     globals()[var_name] = logocv_df\n",
    "    \n",
    "#     # Store the kfold dataframe in the dataframe dictionary\n",
    "#     dataframe_dict[var_name] = logocv_df\n",
    "\n",
    "\n",
    "\n",
    "# Edacs_dft_df_logocv_metal = dataframe_dict[\"Edacs_dft_logocv_metal\"]\n",
    "# Edft_din6_as_df_logocv_metal = dataframe_dict[\"Edft_din6_as_df_logocv_metal\"]\n",
    "# Edft_din6_s_df_logocv_metal = dataframe_dict[\"Edft_din6_s_df_logocv_metal\"]\n",
    "# Edft_din4_x2_df_logocv_metal = dataframe_dict[\"Edft_din4_x2_df_logocv_metal\"]\n",
    "# Edft_din6_df_logocv_metal = dataframe_dict[\"Edft_din6_df_logocv_metal\"]\n",
    "# Edft_din6_s_din4_x2_df_logocv_metal = dataframe_dict[\"Edft_din6_s_din4_x2_df_logocv_metal\"]\n",
    "# Edft_din6_as_din4_x2_df_logocv_metal = dataframe_dict[\"Edft_din6_as_din4_x2_df_logocv_metal\"]\n",
    "# Edft_balanced_df_logocv_metal= dataframe_dict[\"Edft_balanced_df_logocv_metal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and preparing DFT energy datasets with Cavity Leave-One-Group-Out Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section prepares the adsorption energy datasets for machine learning by applying **Leave-One-Group-Out Cross-Validation (LOGO-CV)** using the structural property or any other desirable property **`cavity_3`** as the grouping variable.\n",
    "\n",
    "> âš ï¸ **Note**: The entire code block is currently **commented out**.  \n",
    "> To activate it, **uncomment** all the lines by removing the leading `#` symbols.\n",
    "\n",
    "#### âœ… Key functionality:\n",
    "- Loads several `.pkl` data files containing DFT-calculated adsorption energies.\n",
    "- Applies LOGO-CV using the `add_cv_columns()` function, grouping by the `cavity_3` column.\n",
    "- Dynamically creates variables (e.g., `Edft_din6_as_df_logocv_cavity`) and stores them in a dictionary (`dataframe_dict`) for easy access.\n",
    "\n",
    "> ğŸ” This cross-validation setup is used to assess model generalizability across different **cavity types**, making it particularly useful for structure-driven performance predictions.\n",
    "\n",
    "â¡ï¸ Youâ€™ll need to **uncomment this section** before training models that use `cavity_3`-based LOGO-CV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"../../../data/external/dacs_energies_out\"\n",
    "\n",
    "# # Define the file names and corresponding variable names\n",
    "# file_variables = {\n",
    "#     \"Edacs_dft.pkl\": \"Edacs_dft\",\n",
    "#     \"Edft_din6_as_df.pkl\":\"Edft_din6_as_df\",\n",
    "#     \"Edft_din6_s_df.pkl\":\"Edft_din6_s_df\",\n",
    "#     \"Edft_din4_x2_df.pkl\":\"Edft_din4_x2_df\",\n",
    "#     \"Edft_din6_df.pkl\":\"Edft_din6_df\",\n",
    "#     \"Edft_din6_s_din4_x2_df.pkl\":\"Edft_din6_s_din4_x2_df\",\n",
    "#     \"Edft_din6_as_din4_x2_df.pkl\":\"Edft_din6_as_din4_x2_df\",\n",
    "#     \"Edft_balanced_df.pkl\": \"Edft_balanced_df\"\n",
    "#     } \n",
    "\n",
    "# # Create an empty dictionary to store the DataFrames\n",
    "# data_frames = {}\n",
    "\n",
    "# # Iterate over the file_variables dictionary\n",
    "# for file_name, variable_name in file_variables.items():\n",
    "#     file_path = os.path.join(data_dir, file_name)\n",
    "#     data_frame = pd.read_pickle(file_path)\n",
    "#     data_frames[variable_name] = data_frame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Iterate over the file_variables dictionary\n",
    "# for file_name, variable_name in file_variables.items():\n",
    "#     file_path = os.path.join(data_dir, file_name)\n",
    "#     data_frame = pd.read_pickle(file_path)\n",
    "#     data_frames[variable_name] = data_frame\n",
    "\n",
    "\n",
    "# cv_setup = {\"cv_type\": \"logocv\", \"cv_spec\": 'cavity_3'}\n",
    "\n",
    "\n",
    "# # Create a dictionary to store the dataframes for easy access\n",
    "# dataframe_dict = {}\n",
    "\n",
    "# # Iterate over the data_frames dictionary\n",
    "# for key, df in data_frames.items():\n",
    "#     # Apply the add_cv_columns function to each dataframe\n",
    "#     logocv_df = add_cv_columns(df_in=df, cv_setup=cv_setup)\n",
    "#     # Create a variable name based on the original dataframe name with \"_kfold\" appended\n",
    "#     var_name = key + \"_logocv_cavity\"\n",
    "#     # Assign the kfold dataframe to the dynamically\n",
    "#     globals()[var_name] = logocv_df\n",
    "    \n",
    "#     # Store the kfold dataframe in the dataframe dictionary\n",
    "#     dataframe_dict[var_name] = logocv_df\n",
    "\n",
    "\n",
    "# # TODO: Write within a loop and have access at any point of the code\n",
    "\n",
    "# Edacs_dft_df_logocv_cavity = dataframe_dict[\"Edacs_dft_logocv_cavity\"]\n",
    "# Edft_din6_as_df_logocv_cavity = dataframe_dict[\"Edft_din6_as_df_logocv_cavity\"]\n",
    "# Edft_din6_s_df_logocv_cavity = dataframe_dict[\"Edft_din6_s_df_logocv_cavity\"]\n",
    "# Edft_din4_x2_df_logocv_cavity = dataframe_dict[\"Edft_din4_x2_df_logocv_cavity\"]\n",
    "# Edft_din6_df_logocv_cavity = dataframe_dict[\"Edft_din6_df_logocv_cavity\"]\n",
    "# Edft_din6_s_din4_x2_df_logocv_cavity = dataframe_dict[\"Edft_din6_s_din4_x2_df_logocv_cavity\"]\n",
    "# Edft_din6_as_din4_x2_df_logocv_cavity = dataframe_dict[\"Edft_din6_as_din4_x2_df_logocv_cavity\"]\n",
    "# Edft_balanced_df_logocv_cavity= dataframe_dict[\"Edft_balanced_df_logocv_cavity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Space and Target Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TARGET VARIABLE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "target = \"E_dft_M1M2\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# METAL FEATURES \n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "metal_features = [\n",
    "    \"atomic_mass\",\n",
    "    \"vdw_radius\",\n",
    "    \"r_cov_sb\",\n",
    "    \"r_cov_db\",\n",
    "    \"dipole_polarizability\",\n",
    "    \"ionic_radii_crystals\",\n",
    "    \"d_center_sp\",\n",
    "    \"Paul_electroneg\",\n",
    "    \"MB_electroneg\",\n",
    "    \"electron_affinity\",\n",
    "    \"covalent_radius\",\n",
    "    \"atomic_number\",\n",
    "    \"Ion_energ_I\",\n",
    "    \"Ion_energ_II\",\n",
    "    \"Zung_radius\",\n",
    "    \"Coh_radius\",\n",
    "    \"Waber_radius\",\n",
    "    \"mied_param_h\",\n",
    "    \"mied_param_phi\",\n",
    "    \"HOMO \",\n",
    "    \"LUMO\",\n",
    "    \"mag_moment_bulk_d\",\n",
    "    \" E_Fermi\",\n",
    "    \"E_Fermi2\",  \n",
    "]\n",
    " \n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CAVITY FEATURES\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cavity_features = [\n",
    "    \"ncoord\",\n",
    "    \"number_hetero\",\n",
    "    \"number_C\",\n",
    "    \"frac_hetero\",\n",
    "    \"frac_C\",\n",
    "    \"number_hetero_six\",\n",
    "    \"frac_hetero_six\",\n",
    "    \"number_hetero_five\",\n",
    "    \"frac_hetero_five\",\n",
    "    'delta_min_ds', \n",
    "    'delta_max_ds',\n",
    "    'fermi_energy_cavity',\n",
    "    'surface',\n",
    "    'convex_hull_area',\n",
    "    'convex_hull_volume'\n",
    "]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ELECTRONEGATIVITIES AND ATOMIC RADIUS FEATURES\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "en_features = ['min(en)', 'mean(en)', 'max(en)', 'std(en)', 'sum(en)']\n",
    "r_features = ['min(r)', 'mean(r)', 'max(r)', 'std(r)', 'sum(r)']\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# GEOMETRICAL FEATURES\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \n",
    "posc_cd_features = ['min(posc_cavity_ds)', 'max(posc_cavity_ds)', 'mean(posc_cavity_ds)', 'std(posc_cavity_ds)',]\n",
    "                    #'min(posc_cavity_ang)', 'max(posc_cavity_ang)', 'mean(posc_cavity_ang)','std(posc_cavity_ang)']\n",
    "\n",
    "\n",
    "cont_cd_features = ['min(cont_cavity_ds)', 'max(cont_cavity_ds)', 'mean(cont_cavity_ds)', 'std(cont_cavity_ds)',]\n",
    "                    #'min(cont_cavity_ang)','max(cont_cavity_ang)', 'mean(cont_cavity_ang)', 'std(cont_cavity_ang)']\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CROSS VALIDATION\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cv_types = ['kfold', 'metal', 'cavity']\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# PRIMARY FEATURES\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "primary_features = metal_features + cavity_features + en_features + r_features + posc_cd_features + cont_cd_features\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# FEATURE SETS\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "primary_feature_sets = {\n",
    "    'metal': metal_features,\n",
    "    'cavity': cavity_features,\n",
    "    'full': primary_features,\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# SELECTED FEATURES FROM RF-SFS FOR SACs ON DOPED CARBON\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "selected_features = ['surface', \n",
    "                     \"mied_param_h\", \n",
    "                     'fermi_energy_cavity',\n",
    "                     \"r_cov_sb\",\n",
    "                     'sum(r)', \n",
    "                     \"MB_electroneg\", \n",
    "                     \"ncoord\", \n",
    "                     \" E_Fermi\",                \n",
    "                     ]\n",
    "\n",
    "trial_feature_sets = [\n",
    "    # metal_features,\n",
    "    # cavity_features,\n",
    "    # metal_features + cavity_features,\n",
    "    # metal_features + cavity_features + en_features,\n",
    "    # metal_features + cavity_features + r_features,\n",
    "    # metal_features + cavity_features + en_features + r_features,\n",
    "    # metal_features + cavity_features + en_features + r_features + posc_cd_features,\n",
    "    # metal_features + cavity_features + en_features + r_features + cont_cd_features,\n",
    "    # metal_features + cavity_features + en_features + r_features + posc_cd_features + cont_cd_features,\n",
    "    selected_features \n",
    "\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Parameter                  | Description                                                                 |\n",
    "|---------------------------|-----------------------------------------------------------------------------|\n",
    "| `bootstrap`               | Whether bootstrap samples are used when building trees (`True` = yes).      |\n",
    "| `ccp_alpha`               | Complexity parameter used for Minimal Cost-Complexity Pruning (`0.0` = no pruning). |\n",
    "| `criterion`               | Function to measure the quality of a split (`squared_error` = MSE).         |\n",
    "| `max_depth`               | Maximum depth of each decision tree (`8` here limits model complexity).     |\n",
    "| `max_features`            | Fraction of features considered at each split (`0.4` = 40% of total features). |\n",
    "| `max_leaf_nodes`          | Limits the number of leaf nodes in each tree (`None` = unlimited).          |\n",
    "| `max_samples`             | Number or fraction of samples to draw from X to train each base estimator (`None` = use all). |\n",
    "| `min_impurity_decrease`   | Node split occurs only if the impurity decrease is at least this value.     |\n",
    "| `min_samples_leaf`        | Minimum number of samples required to be at a leaf node (`1` = default).    |\n",
    "| `min_samples_split`       | Minimum number of samples required to split an internal node (`2` = default). |\n",
    "| `min_weight_fraction_leaf`| Minimum weighted fraction of the sum total of weights required to be at a leaf node. |\n",
    "| `n_estimators`            | Number of trees in the forest (`128` = moderately sized forest).            |\n",
    "| `n_jobs`                  | Number of jobs to run in parallel (`-1` = use all available cores).         |\n",
    "| `oob_score`               | Whether to use out-of-bag samples to estimate generalization accuracy (`False` = no). |\n",
    "| `random_state`            | Controls randomness for reproducibility (`0` = fixed seed).                 |\n",
    "| `verbose`                 | Controls the verbosity of the output (`0` = silent mode).                   |\n",
    "| `warm_start`              | If `True`, reuse solution of the previous call to `fit` and add more estimators. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# RANDOM FOREST DICTIONARY\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "rf_dict = {\n",
    "    \"bootstrap\": True,\n",
    "    \"ccp_alpha\": 0.0,\n",
    "    \"criterion\": \"squared_error\",\n",
    "    \"max_depth\":8, #8\n",
    "    \"max_features\": 0.4,\n",
    "    \"max_leaf_nodes\": None,\n",
    "    \"max_samples\":None,\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    # \"min_impurity_split\": None,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    \"n_estimators\": 128,#128,\n",
    "    \"n_jobs\": -1,\n",
    "    \"oob_score\": False,\n",
    "    \"random_state\": 0,\n",
    "    \"verbose\": 0,\n",
    "    \"warm_start\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `evaluate_features_rf` function automates the process of training and evaluating a Random Forest Regression model across multiple feature sets.\n",
    "\n",
    "##### Function Inputs\n",
    "- `df_in` (`pd.DataFrame`): The input dataframe containing the features, target, and metadata (e.g., system labels).\n",
    "- `feature_sets` (`list of lists`): A list where each element is a list of feature names to be evaluated as a group.\n",
    "- `rf_dict` (`dict`): A dictionary specifying the hyperparameters for the `RandomForestRegressor`. This allows full control over the model configuration.\n",
    "- `target` (`str`): The name of the column in `df_in` that will be used as the regression target.\n",
    "\n",
    "##### What It Does\n",
    "For each set of features:\n",
    "1. Fits a `RandomForestRegressor` using the specified hyperparameters and target.\n",
    "2. Extracts and prints the feature importances.\n",
    "3. Uses a plotting utility to visualize predicted vs. actual values on both training and test sets.\n",
    "4. Appends the best-performing model's plot to a list of figures.\n",
    "5. Saves the result dataframe and error metrics to disk.\n",
    "\n",
    "##### Output\n",
    "- Returns a list of `plotly.graph_objects.Figure` objects â€” one for each feature set evaluated â€” that visualize the regression results.\n",
    "- Saves:\n",
    "  - A CSV of the prediction results (`df_rfr_dacs_results_metal_logocv.csv`)\n",
    "  - A CSV of the error metrics (`data_errors_mlogocv.csv`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFR with k-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Fold\n",
    "\n",
    "#%%capture\n",
    "figs = evaluate_features_rf(df_in=Edft_balanced_df_kfold, feature_sets=trial_feature_sets,rf_dict=rf_dict,\n",
    "    target=target)\n",
    "for fig in figs:\n",
    "#     pio.write_image(fig, '../../../data/figures/rfr_results/rfr_selected_features.svg', format='svg')\n",
    "#     pio.write_image(fig, '../../../data/figures/rfr_results/rfr_selected_features.png', format='png',scale = 3)\n",
    "#     pio.write_image(fig, '../../../data/figures/rfr_results/rfr_selected_features.pdf', format='pdf')\n",
    "      fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFR with Dual-Metal LOGOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Dual Metal LOGOCV\n",
    "\n",
    "# #%%capture\n",
    "# figs = evaluate_features_rf(df_in=Edft_balanced_df_logocv_metal, feature_sets=trial_feature_sets, rf_dict=rf_dict,\n",
    "#      target=target)\n",
    "# for fig in figs:\n",
    "#     # pio.write_image(fig, '../../../data/figures/rfr_results/rfr_metal_logocv.svg', format='svg')\n",
    "#     # pio.write_image(fig, '../../../data/figures/rfr_results/rfr_metal_logocv.png', format='png',scale = 3)\n",
    "#     # pio.write_image(fig, '../../../data/figures/rfr_results/rfr_metal_logocv.pdf', format='pdf')\n",
    "#     fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFR with Cavity LOGOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Dual Metal LOGOCV\n",
    "\n",
    "# #%%capture\n",
    "# figs = evaluate_features_rf(df_in=Edft_balanced_df_logocv_cavity, feature_sets=trial_feature_sets, rf_dict=rf_dict,\n",
    "#      target=target)\n",
    "# for fig in figs:\n",
    "#     # pio.write_image(fig, '../../../data/figures/rfr_results/rfr_cavity_logocv.svg', format='svg')\n",
    "#     # pio.write_image(fig, '../../../data/figures/rfr_results/rfr_cavity_logocv.png', format='png',scale = 3)\n",
    "#     # pio.write_image(fig, '../../../dacs_ml/data/figures/rfr_results/rfr_cavity_logocv.pdf', format='pdf')\n",
    "#     fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning for RFR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs hyperparameter tuning for a `RandomForestRegressor` by varying the `max_depth`. It evaluates model performance using selected features and returns an error plot showing training and test errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_dict = {\n",
    "    \"bootstrap\": True,\n",
    "    \"ccp_alpha\": 0.0,\n",
    "    \"criterion\": \"squared_error\",\n",
    "    #\"max_depth\":8, #8\n",
    "    \"max_features\": 0.4,\n",
    "    \"max_leaf_nodes\": None,\n",
    "    \"max_samples\":None,\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    # \"min_impurity_split\": None,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    \"n_estimators\": 128,#128,\n",
    "    \"n_jobs\": -1,\n",
    "    \"oob_score\": False,\n",
    "    \"random_state\": 0,\n",
    "    \"verbose\": 0,\n",
    "    \"warm_start\": False,\n",
    "}\n",
    "\n",
    "\n",
    "rf_estimator_dict = vary_ml_param(\n",
    "    df_in=Edft_balanced_df_kfold,\n",
    "    ml_base_model=RandomForestRegressor(**rf_dict),\n",
    "    ml_features=selected_features,\n",
    "    ml_targets=target,\n",
    "    ml_param_dict={'max_depth': list(range(1, 16, 2))},\n",
    "    verbose=False,  \n",
    "    color_setup=color_setup \n",
    "    )\n",
    "\n",
    "rf_estimator_dict['error_fig'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs hyperparameter tuning for a `RandomForestRegressor` by varying the `n_estimators`. It evaluates model performance using selected features and returns an error plot showing training and test errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_dict = {\n",
    "    \"bootstrap\": True,\n",
    "    \"ccp_alpha\": 0.0,\n",
    "    \"criterion\": \"squared_error\",\n",
    "    \"max_depth\":8, #8\n",
    "    \"max_features\": 0.4,\n",
    "    \"max_leaf_nodes\": None,\n",
    "    \"max_samples\":None,\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    # \"min_impurity_split\": None,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    #\"n_estimators\": 128,#128,\n",
    "    \"n_jobs\": -1,\n",
    "    \"oob_score\": False,\n",
    "    \"random_state\": 0,\n",
    "    \"verbose\": 0,\n",
    "    \"warm_start\": False,\n",
    "}\n",
    "\n",
    "\n",
    "rf_estimator_dict = vary_ml_param(\n",
    "    df_in=Edft_balanced_df_kfold,\n",
    "    ml_base_model=RandomForestRegressor(**rf_dict),\n",
    "    ml_features=selected_features,\n",
    "    ml_targets=target,\n",
    "    ml_param_dict={'n_estimators': list(range(1, 350, 50))},\n",
    "    verbose=False,  \n",
    "    color_setup=color_setup \n",
    "    )\n",
    "\n",
    "\n",
    "rf_estimator_dict['error_fig'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs hyperparameter tuning for a `RandomForestRegressor` by varying the `max_features`. It evaluates model performance using selected features and returns an error plot showing training and test errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_dict = {\n",
    "    \"bootstrap\": True,\n",
    "    \"ccp_alpha\": 0.0,\n",
    "    \"criterion\": \"squared_error\",\n",
    "    \"max_depth\":8, #8\n",
    "    #\"max_features\": 0.4,#0.4\n",
    "    \"max_leaf_nodes\": None,\n",
    "    \"max_samples\":None,\n",
    "    \"min_impurity_decrease\": 0.0,\n",
    "    # \"min_impurity_split\": None,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    \"n_estimators\": 128,#128,\n",
    "    \"n_jobs\": -1,\n",
    "    \"oob_score\": False,\n",
    "    \"random_state\": 0,\n",
    "    \"verbose\": 0,\n",
    "    \"warm_start\": False,\n",
    "}\n",
    "\n",
    "\n",
    "rf_estimator_dict = vary_ml_param(\n",
    "    df_in=Edft_balanced_df_kfold,\n",
    "    ml_base_model=RandomForestRegressor(**rf_dict),\n",
    "    ml_features=selected_features,\n",
    "    ml_targets=target,\n",
    "    ml_param_dict={'max_features': np.linspace(0.1, 1, 10)},\n",
    "    verbose=False,  \n",
    "    color_setup=color_setup \n",
    "    )\n",
    "\n",
    "\n",
    "rf_estimator_dict['error_fig'].show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
